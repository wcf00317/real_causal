data:
  type: "gta5_to_cityscapes"
  train_dataset_path: "/data/chengfengwu/alrl/mtl_dataset/gta5/train"
  val_dataset_path: "/data/chengfengwu/alrl/mtl_dataset/cityscape_preprocess"
  source_val_path: "/data/chengfengwu/alrl/mtl_dataset/gta5/val"
  batch_size: 32
  num_workers: 4
  img_size: [128, 256]
  pin_memory: True

model:
  type: "causal"
  encoder_name: "resnet50"
  pretrained: True
  num_seg_classes: 7
  latent_dim_s: 1024
  latent_dim_p: 64
  z_s_bottleneck_noise: 0.1

  decomposition:
    enabled: true
    normal_head_hidden: 128
    albedo_head_hidden: 128
    light_head:
      sh_degree: 2
      grayscale_prior: true

training:
  seed: 2024
  epochs: 100
  optimizer: "AdamW"
  learning_rate: 0.0002
  weight_decay: 0.0001

  # === 阶段控制 (SOTA 策略) ===
  stage0_epochs: 10
  stage1_epochs: 5
  ind_warmup_epochs: 30  # 锁定30，黄金平衡点

  lr_scheduler:
    type: "cosine"
    warmup_epochs: 10
    min_lr_factor: 0.01

  # === 反事实增强 (CFA) ===
  cfa:
    enabled: true
    start_epoch: 35      # 提前到35，抢占泛化窗口期
    prob: 0.5            # 保持强度
    lambda_cfa: 0.5
    mix_strategy: "global"

losses:
  # === 任务 Loss (高能双驱) ===
  lambda_seg: 30.0    # 暴力提权，冲击 mIoU > 0.58
  lambda_depth: 25.0  # 同步跟进，稳住 Abs Err < 0.10

  # 【防报错补全】显式设为 0.0
  lambda_normal: 0.0
  lambda_edge_consistency: 0.0  # 必须是 0！防 Rel Err 爆炸

  # === 独立性 Loss ===
  lambda_independence: 0.1 #

  # === 重构 Loss (SOTA 策略) ===
  # 【关键】就是这个键漏了导致的报错，现在补上了！
  # 设为 5.0，既让物理约束生效，又不引入太多噪声
  alpha_recon_geom: 5.0

  beta_recon_app: 2.0
  lambda_l1_recon: 2.0

  # === 物理先验 (全部补齐) ===
  lambda_img: 5.0      # 物理渲染重构权重
  lambda_alb_tv: 0.1   # 纹理平滑
  lambda_sh_gray: 0.1  # 光照约束
  lambda_xcov: 0.5     # 去相关