import yaml, json
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import os, argparse
import logging
from datetime import datetime

# --- æ•°æ®é›†å¯¼å…¥ ---
from data_utils.nyuv2_dataset import NYUv2Dataset
from data_utils.gta5_dataset import GTA5Dataset
from data_utils.cityscapes_dataset import CityscapesDataset

# --- æ¨¡å‹ä¸Losså¯¼å…¥ (ä»…ä¿ç•™ Causal æ ¸å¿ƒ) ---
from models.causal_model import CausalMTLModel
from losses.composite_loss import CompositeLoss

# --- å¼•æ“å·¥å…·å¯¼å…¥ ---
from engine.trainer import train
from engine.visualizer import generate_visual_reports
from engine.experiments import run_all_experiments
from utils.general_utils import set_seed, setup_logging


def main(config_path):
    """
    é¡¹ç›®ä¸»å‡½æ•°ï¼ˆæ”¯æŒåŒéªŒè¯é›† Dual Validationï¼‰ã€‚
    """
    # 1. åŠ è½½é…ç½®å¹¶è®¾ç½®éšæœºç§å­
    try:
        with open(config_path, 'r') as f:
            config = yaml.safe_load(f)
        set_seed(config['training']['seed'])
    except Exception as e:
        logging.info(f"âŒ Error loading config file: {e}")
        return

    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M')
    run_dir = os.path.join('runs', timestamp)
    checkpoint_dir = os.path.join(run_dir, 'checkpoints')
    vis_dir = os.path.join(run_dir, 'visualizations')
    os.makedirs(checkpoint_dir, exist_ok=True)
    os.makedirs(vis_dir, exist_ok=True)
    setup_logging(run_dir)
    logging.info("âœ… Configuration loaded successfully.")
    logging.info(f"ğŸ“‚ All outputs for this run will be saved in: {run_dir}")
    logging.info("=" * 60)
    logging.info("ğŸ”§ Final Execution Configuration:")
    logging.info(json.dumps(config, indent=4, default=str))
    logging.info("=" * 60)

    # 2. è®¾ç½®è®¡ç®—è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"ğŸš€ Using device: {device}")

    # 3. åˆå§‹åŒ–æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    logging.info("\nInitializing dataset...")
    try:
        data_cfg = config['data']
        dataset_type = data_cfg.get('type', 'nyuv2').lower()
        img_size = tuple(data_cfg['img_size'])
        dataset_path = data_cfg.get('dataset_path')

        logging.info(f"ğŸ“‹ Dataset Type: {dataset_type}")

        # åˆå§‹åŒ–å˜é‡
        train_dataset = None
        val_dataset_tgt = None  # ç›®æ ‡åŸŸéªŒè¯é›† (Target)
        val_dataset_src = None  # æºåŸŸéªŒè¯é›† (Source) - å¯é€‰

        # === æ•°æ®é›†åŠ è½½é€»è¾‘ ===
        if dataset_type == 'gta5_to_cityscapes':
            logging.info("ğŸŒ Mode: GTA5 -> Cityscapes (Dual Validation)")

            # 1. è®­ç»ƒé›† (GTA5 Train) - å¼€å¯å¢å¼º
            train_dataset = GTA5Dataset(
                root_dir=data_cfg['train_dataset_path'],
                img_size=img_size,
                augmentation=True  # <--- è®­ç»ƒå¼€å¯å¢å¼º
            )

            # 2. ç›®æ ‡åŸŸéªŒè¯é›† (Cityscapes Val)
            val_dataset_tgt = CityscapesDataset(
                root_dir=data_cfg['val_dataset_path'],
                split='val'
            )

            # 3. æºåŸŸéªŒè¯é›† (GTA5 Val) - å…³é—­å¢å¼º
            # åªæœ‰åœ¨ config ä¸­æä¾›äº† source_val_path æ‰åŠ è½½
            if 'source_val_path' in data_cfg:
                val_dataset_src = GTA5Dataset(
                    root_dir=data_cfg['source_val_path'],
                    img_size=img_size,
                    augmentation=False  # <--- éªŒè¯å¿…é¡»å…³é—­å¢å¼º
                )

        elif dataset_type == 'cityscapes':
            logging.info("ğŸŒ Mode: Cityscapes")
            train_dataset = CityscapesDataset(root_dir=dataset_path, split='train')
            val_dataset_tgt = CityscapesDataset(root_dir=dataset_path, split='val')

        elif dataset_type == 'nyuv2':
            logging.info("ğŸ  Mode: NYUv2")
            train_dataset = NYUv2Dataset(root_dir=dataset_path, mode='train',
                                         augmentation=data_cfg.get('augmentation', False))
            val_dataset_tgt = NYUv2Dataset(root_dir=dataset_path, mode='val')

        else:
            raise ValueError(f"âŒ Unsupported dataset type: '{dataset_type}'")

        # DataLoader è®¾ç½®
        pin_memory = data_cfg.get('pin_memory', torch.cuda.is_available())

        # è®­ç»ƒ Loader
        train_loader = DataLoader(
            train_dataset,
            batch_size=data_cfg['batch_size'],
            shuffle=True,
            num_workers=data_cfg['num_workers'],
            pin_memory=pin_memory,
            drop_last=True
        )

        # ç›®æ ‡åŸŸéªŒè¯ Loader (é»˜è®¤)
        val_loader_tgt = DataLoader(
            val_dataset_tgt,
            batch_size=data_cfg['batch_size'],
            shuffle=False,
            num_workers=data_cfg['num_workers'],
            pin_memory=pin_memory
        )

        # æºåŸŸéªŒè¯ Loader (å¯é€‰)
        val_loader_src = None
        if val_dataset_src is not None:
            val_loader_src = DataLoader(
                val_dataset_src,
                batch_size=data_cfg['batch_size'],
                shuffle=False,
                num_workers=data_cfg['num_workers'],
                pin_memory=pin_memory
            )
            logging.info(f"ğŸ“š Dual Validation Enabled: Source (GTA5) & Target (Cityscapes)")

        logging.info(f"ğŸ“š Dataset loaded: {len(train_dataset)} training, {len(val_dataset_tgt)} target val samples.")

    except Exception as e:
        logging.info(f"âŒ Error creating dataset/loaders: {e}")
        import traceback
        traceback.print_exc()
        return

    # 4. åˆå§‹åŒ–æ¨¡å‹ (CausalMTLModel Only)
    logging.info("\nInitializing CausalMTLModel...")
    base_lr = float(config['training']['learning_rate'])

    # ç›´æ¥å®ä¾‹åŒ– CausalMTLModel
    model = CausalMTLModel(config['model'], config['data']).to(device)

    # å‚æ•°åˆ†ç»„ï¼šBackbone vs Heads
    backbone_params = []
    head_params = []

    for name, param in model.named_parameters():
        if 'encoder' in name:
            backbone_params.append(param)
        else:
            head_params.append(param)

    # ä¼˜åŒ–å™¨é…ç½®
    optimizer = optim.Adam([
        {'params': backbone_params, 'lr': base_lr},
        {'params': head_params, 'lr': base_lr}
    ], lr=base_lr, weight_decay=config['training']['weight_decay'])

    # Loss é…ç½® (ä»…ä½¿ç”¨ CompositeLoss)
    criterion = CompositeLoss(config['losses'].copy(), dataset_type).to(device)

    logging.info(f"ğŸ”§ Optimizer: {config['training']['optimizer']}, LR: {base_lr}")

    # 5. å­¦ä¹ ç‡è°ƒåº¦å™¨ (Trainer å†…éƒ¨æ„å»ºï¼Œæ­¤å¤„ä¼  None)
    scheduler = None

    # 6. å¯åŠ¨è®­ç»ƒ
    logging.info("\n----- Starting Training -----")
    if config['training'].get('enable_training', True):
        # æ³¨æ„ï¼šè¿™é‡Œä¼ é€’äº†ä¸¤ä¸ªéªŒè¯ Loader
        train(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader_tgt,  # ç›®æ ‡åŸŸ (Cityscapes)
            optimizer=optimizer,
            criterion=criterion,
            scheduler=scheduler,
            config=config,
            device=device,
            checkpoint_dir=checkpoint_dir,
            val_loader_source=val_loader_src  # æºåŸŸ (GTA5) - å¯é€‰
        )
    else:
        logging.info("ğŸƒ Training is disabled in config.")

    # 7. å®éªŒæ€§åˆ†æ
    exp_cfg = config.get('experiments', {})
    if exp_cfg.get('enable', False):
        logging.info("\n===== Running experiments =====")
        model.eval()
        run_all_experiments(model, val_loader_tgt, device)

    # 8. å¯è§†åŒ– (ä½¿ç”¨ç›®æ ‡åŸŸæ•°æ®)
    logging.info("\n----- Running Final Visualizations -----")
    best_ckpt = os.path.join(checkpoint_dir, 'model_best.pth.tar')
    if os.path.exists(best_ckpt):
        try:
            checkpoint = torch.load(best_ckpt, map_location=device)
            model.load_state_dict(checkpoint['state_dict'], strict=False)
            generate_visual_reports(model, val_loader_tgt, device, save_dir=vis_dir, num_reports=3)
        except Exception as e:
            logging.info(f"âš ï¸ Visualization failed: {e}")

    if hasattr(train_dataset, "close"): train_dataset.close()
    if hasattr(val_dataset_tgt, "close"): val_dataset_tgt.close()

    logging.info("\nğŸ‰ Done.")


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', type=str, default='configs/resnet50_nyuv2.yaml')
    args = parser.parse_args()
    main(args.config)