import os
import argparse
import yaml
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from torch.utils.data import DataLoader
from tqdm import tqdm

# --- Project Modules ---
# ç¡®ä¿è¿™äº›æ¨¡å—è·¯å¾„åœ¨æ‚¨çš„é¡¹ç›®ä¸­æ˜¯æ­£ç¡®çš„
from models.causal_celeba_model import CausalCelebAModel
from data_utils.celeba_dataset import CelebADataset
from utils.general_utils import set_seed


def parse_args():
    parser = argparse.ArgumentParser(description="Verify Subspace Orthogonality (Zs vs Zp)")
    parser.add_argument('--config', type=str, required=True, help="Path to config file")
    parser.add_argument('--checkpoint', type=str, default=None, help="Path to model checkpoint")
    parser.add_argument('--output', type=str, default='orthogonality_check.png', help="Output plot filename")
    parser.add_argument('--device', type=str, default='cuda', help="Device (cuda/cpu)")
    parser.add_argument('--batches', type=int, default=10, help="Number of batches to evaluate")
    return parser.parse_args()


def load_config(path):
    with open(path, 'r') as f:
        return yaml.safe_load(f)


def main():
    args = parse_args()
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Using device: {device}")

    # 1. Load Config
    print(f"ğŸ“‚ Loading config: {args.config}")
    config = load_config(args.config)

    # [Fix] å¼ºåˆ¶è®¾ç½® num_attributes ä¸º 40ï¼Œä»¥åŒ¹é… Checkpoint çš„æƒé‡å½¢çŠ¶
    # è¿™æ˜¯ä¸ºäº†è§£å†³ä¹‹å‰é‡åˆ°çš„æƒé‡åŠ è½½æŠ¥é”™é—®é¢˜
    print("ğŸ”§ Forcing num_attributes=40 to match standard CelebA checkpoint...")
    config['model']['num_attributes'] = 40

    set_seed(config['training'].get('seed', 2024))

    # 2. Dataset
    data_cfg = config['data']
    print(f"ğŸ“š Initializing CelebA Dataset (Val split)...")
    # è¿™é‡Œå¼ºåˆ¶ num_attributes=40ï¼Œç¡®ä¿æ•°æ®ä¸æ¨¡å‹å¤´å¯¹é½
    dataset = CelebADataset(
        root_dir=data_cfg['dataset_path'],
        split='val',
        img_size=data_cfg.get('img_size', [128, 128]),
        num_attributes=40,
        augmentation=False
    )
    loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)

    # 3. Model
    print("ğŸ§  Initializing CausalCelebAModel...")
    model = CausalCelebAModel(config['model']).to(device)

    # 4. Load Checkpoint
    if args.checkpoint and os.path.exists(args.checkpoint):
        print(f"ğŸ“¥ Loading checkpoint: {args.checkpoint}")
        ckpt = torch.load(args.checkpoint, map_location=device)
        state_dict = ckpt['state_dict'] if 'state_dict' in ckpt else ckpt
        model.load_state_dict(state_dict, strict=False)
    else:
        print("âš ï¸ No checkpoint provided! Results will be random.")

    model.eval()

    # Losses
    criterion_attr = nn.BCEWithLogitsLoss()
    criterion_recon = nn.L1Loss()

    cosine_sims = []

    print(f"âš¡ Running orthogonality check on {args.batches} batches...")

    for i, batch in enumerate(tqdm(loader, total=args.batches)):
        if i >= args.batches:
            break

        imgs = batch['image'].to(device)
        attrs = batch['attributes'].to(device)  # [B, 40]

        # å³ä½¿åœ¨ eval æ¨¡å¼ä¸‹ï¼Œä¹Ÿå¯ç”¨æ¢¯åº¦è®¡ç®—ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦å¯¹ input æ±‚å¯¼ï¼ˆæˆ–ç‰¹å¾å±‚æ±‚å¯¼ï¼‰
        with torch.set_grad_enabled(True):
            imgs.requires_grad_(True)

            # --- æ‰‹åŠ¨åˆ†æ­¥å‰å‘ä¼ æ’­ ---
            # 1. Encoder æå–ç‰¹å¾
            feat_map = model.encoder(imgs)
            feat_map.retain_grad()  # å…³é”®æ­¥éª¤ï¼šä¿ç•™ä¸­é—´å±‚ç‰¹å¾çš„æ¢¯åº¦

            # 2. åˆ†æ”¯æŠ•å½±
            zs_map = model.proj_zs(feat_map)
            zp_map = model.proj_zp(feat_map)

            # 3. å±æ€§ä»»åŠ¡ (Zs è·¯å¾„)
            zs_vec = F.adaptive_avg_pool2d(zs_map, (1, 1)).flatten(1)
            pred_attr = model.attr_head(zs_vec)

            # 4. é‡æ„ä»»åŠ¡ (Zs + Zp è·¯å¾„)
            z_combined = torch.cat([zs_map, zp_map], dim=1)
            recon_img = model.decoder(z_combined)

            # --- æ¢¯åº¦è®¡ç®— ---

            # A. è®¡ç®— Attribute Loss å¯¹ Encoder ç‰¹å¾çš„æ¢¯åº¦
            model.zero_grad()
            if feat_map.grad is not None: feat_map.grad.zero_()

            loss_attr = criterion_attr(pred_attr, attrs)
            loss_attr.backward(retain_graph=True)  # ä¿ç•™å›¾ä»¥è¿›è¡Œç¬¬äºŒæ¬¡ backward

            grad_attr = feat_map.grad.clone().detach()  # [B, C, H, W]

            # B. è®¡ç®— Recon Loss å¯¹ Encoder ç‰¹å¾çš„æ¢¯åº¦
            model.zero_grad()
            feat_map.grad.zero_()

            loss_recon = criterion_recon(recon_img, imgs)
            loss_recon.backward()

            grad_recon = feat_map.grad.clone().detach()  # [B, C, H, W]

            # --- è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ ---
            # å±•å¹³ä¸º [B, D]
            g_a_flat = grad_attr.view(grad_attr.size(0), -1)
            g_r_flat = grad_recon.view(grad_recon.size(0), -1)

            # è®¡ç®—ä¸¤ç»„æ¢¯åº¦çš„ä½™å¼¦ç›¸ä¼¼åº¦
            # sim = (A . B) / (|A| |B|)
            sim = F.cosine_similarity(g_a_flat, g_r_flat, dim=1, eps=1e-8)
            cosine_sims.append(sim.cpu().numpy())

    # æ±‡æ€»æ‰€æœ‰ Batch
    all_sims = np.concatenate(cosine_sims)
    mean_sim = np.mean(all_sims)
    std_sim = np.std(all_sims)

    print(f"\nğŸ“Š Results:")
    print(f"  Mean Cosine Similarity: {mean_sim:.4f}")
    print(f"  Std Dev: {std_sim:.4f}")
    print(f"  (Ideal value is close to 0, indicating orthogonality)")

    # 5. å¯è§†åŒ–
    plt.figure(figsize=(10, 6))
    sns.histplot(all_sims, bins=50, kde=True, color='purple', alpha=0.6)
    plt.axvline(0, color='red', linestyle='--', linewidth=2, label='Perfect Orthogonality')
    plt.axvline(mean_sim, color='blue', linestyle='-', linewidth=2, label=f'Mean: {mean_sim:.4f}')

    plt.title("Subspace Orthogonality Check: $\\nabla \mathcal{L}_{attr}$ vs $\\nabla \mathcal{L}_{recon}$",
              fontsize=16)
    plt.xlabel("Cosine Similarity", fontsize=14)
    plt.ylabel("Frequency", fontsize=14)
    plt.legend()
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig(args.output, dpi=150)
    print(f"âœ… Plot saved to {args.output}")


if __name__ == '__main__':
    main()