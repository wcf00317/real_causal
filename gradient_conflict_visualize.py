import os
import argparse
import yaml
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from torch.utils.data import DataLoader

# --- é¡¹ç›®æ¨¡å—å¯¼å…¥ ---
# è¯·ç¡®ä¿è¿™äº›æ–‡ä»¶éƒ½åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹
from models.causal_celeba_model import CausalCelebAModel
from data_utils.celeba_dataset import CelebADataset
from utils.general_utils import set_seed

# CelebA 40ä¸ªå±æ€§çš„æ ‡å‡†åç§°åˆ—è¡¨
CELEBA_ATTRIBUTES = [
    '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald',
    'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',
    'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',
    'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',
    'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',
    'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks',
    'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings',
    'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young'
]


def parse_args():
    parser = argparse.ArgumentParser(description="Generate Gradient Conflict Heatmap for CelebA Attributes")
    parser.add_argument('--config', type=str, required=True,
                        help="Path to the config file (e.g., configs/resnet/5celeba.yaml)")
    parser.add_argument('--checkpoint', type=str, default=None, help="Path to the trained model checkpoint (optional)")
    parser.add_argument('--output', type=str, default='gradient_conflict_heatmap.png',
                        help="Output filename for the heatmap")
    parser.add_argument('--device', type=str, default='cuda', help="Device to use (cuda/cpu)")
    return parser.parse_args()


def load_config(path):
    with open(path, 'r') as f:
        return yaml.safe_load(f)


def compute_cosine_similarity(vecs):
    """
    è®¡ç®—ä¸€ç»„å‘é‡çš„ä¸¤ä¸¤ä½™å¼¦ç›¸ä¼¼åº¦
    Args:
        vecs: [N, D] tensor
    Returns:
        sim_matrix: [N, N] numpy array
    """
    # å½’ä¸€åŒ–
    norm = torch.norm(vecs, p=2, dim=1, keepdim=True)
    vecs_normalized = vecs / (norm + 1e-8)
    # çŸ©é˜µä¹˜æ³•è®¡ç®— Cosine Similarity
    sim_matrix = torch.mm(vecs_normalized, vecs_normalized.t())
    return sim_matrix.cpu().numpy()


def main():
    args = parse_args()
    device = torch.device(args.device if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Using device: {device}")

    # 1. åŠ è½½é…ç½®
    print(f"ğŸ“‚ Loading config: {args.config}")
    config = load_config(args.config)

    # è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¤ç°æ€§
    set_seed(config['training'].get('seed', 2024))

    # 2. åˆå§‹åŒ–æ•°æ®é›† (ä»…éœ€ä¸€ä¸ª Batch)
    data_cfg = config['data']
    print(f"ğŸ“š Initializing CelebA Dataset from {data_cfg['dataset_path']}...")

    # å¼ºåˆ¶ä½¿ç”¨ train é›†ï¼Œå› ä¸ºæˆ‘ä»¬çœ‹çš„æ˜¯è®­ç»ƒæ—¶çš„æ¢¯åº¦å†²çª
    dataset = CelebADataset(
        root_dir=data_cfg['dataset_path'],
        split='train',
        img_size=data_cfg.get('img_size', [128, 128]),
        num_attributes=40,  # å¼ºåˆ¶åˆ†ææ‰€æœ‰40ä¸ªå±æ€§
        augmentation=False  # å…³é—­å¢å¼ºä»¥å‡å°‘éšæœºæ€§å¹²æ‰°åˆ†æ
    )

    loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)

    # è·å–ä¸€ä¸ª Batch çš„æ•°æ®
    try:
        batch = next(iter(loader))
    except StopIteration:
        print("âŒ Error: Dataset is empty.")
        return

    imgs = batch['image'].to(device)
    attrs = batch['attributes'].to(device)  # [B, 40]

    print(f"âœ… Data loaded. Batch shape: {imgs.shape}")

    # 3. åˆå§‹åŒ–æ¨¡å‹
    print("ğŸ§  Initializing CausalCelebAModel...")
    model = CausalCelebAModel(config['model']).to(device)

    # 4. åŠ è½½æƒé‡ (å¦‚æœæœ‰)
    if args.checkpoint and os.path.exists(args.checkpoint):
        print(f"ğŸ“¥ Loading checkpoint: {args.checkpoint}")
        ckpt = torch.load(args.checkpoint, map_location=device)
        state_dict = ckpt['state_dict'] if 'state_dict' in ckpt else ckpt
        model.load_state_dict(state_dict, strict=False)
    else:
        print("âš ï¸ No checkpoint provided or found. Using initialized weights (Analysis might be random).")

    # 5. å‡†å¤‡æ¢¯åº¦åˆ†æ
    model.eval()  # è®¾ä¸º eval æ¨¡å¼ä¸»è¦æ˜¯ä¸ºäº† fix BNï¼Œä½†æˆ‘ä»¬éœ€è¦ grad

    # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½éœ€è¦æ¢¯åº¦ (è™½ç„¶ eval æ¨¡å¼ä¸å½±å“ requires_gradï¼Œä½†ä¿é™©èµ·è§)
    for param in model.parameters():
        param.requires_grad = True

    # === å…³é”®ï¼šå®šä½ Shared Encoder çš„æœ€åä¸€å±‚ ===
    # ResNet18: encoder -> features (Sequential) -> [..., layer4 (Sequential)]
    # æˆ‘ä»¬å– layer4 çš„æœ€åä¸€ä¸ª BasicBlock çš„ç¬¬äºŒä¸ªå·ç§¯å±‚ (conv2) çš„æƒé‡
    # ç†ç”±ï¼šè¿™æ˜¯ç‰¹å¾è¿›å…¥ Task Heads åˆ†å‰å‰ï¼Œæœ€åä¸€ä¸ªåŒ…å«å¯å­¦ä¹ å‚æ•°çš„å±‚
    try:
        # model.encoder æ˜¯ ResNet18Encoder
        # model.encoder.features æ˜¯ Sequential
        # æœ€åä¸€ä¸ªæ˜¯ layer4
        # layer4 æ˜¯ BasicBlock çš„åˆ—è¡¨
        target_layer = model.encoder.backbone.layer4[-1].conv2
        target_param = target_layer.weight
        print(f"ğŸ¯ Target Shared Layer: model.encoder.backbone.layer4[-1].conv2 ({target_param.shape})")
    except AttributeError:
        print("âŒ Error: Could not locate the specific ResNet layer. Please check model structure.")
        return

    # Loss å‡½æ•° (å•å±æ€§ BCE)
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸åŠ  Sigmoidï¼Œå› ä¸º AttributeHead è¾“å‡ºçš„æ˜¯ Logitsï¼Œç”¨ BCEWithLogitsLoss
    criterion = nn.BCEWithLogitsLoss()

    grads = []
    print("\nâš¡ Computing gradients for each of the 40 attributes...")

    # 6. å¾ªç¯è®¡ç®—æ¯ä¸ªå±æ€§çš„æ¢¯åº¦
    for i in range(40):
        # æ¸…é›¶æ¢¯åº¦
        model.zero_grad()

        # å‰å‘ä¼ æ’­
        outputs = model(imgs)
        pred_logits = outputs['pred_attr']  # [B, 40]

        # æå–å½“å‰ä»»åŠ¡çš„é¢„æµ‹å’Œæ ‡ç­¾
        task_pred = pred_logits[:, i]
        task_gt = attrs[:, i].float()

        # è®¡ç®—è¯¥ä»»åŠ¡çš„ Loss
        loss = criterion(task_pred, task_gt)

        # åå‘ä¼ æ’­
        loss.backward()

        # è·å–ç›®æ ‡å±‚çš„æ¢¯åº¦å¹¶å±•å¹³
        if target_param.grad is not None:
            g = target_param.grad.view(-1).clone().detach()
            grads.append(g)
        else:
            print(f"âš ï¸ Warning: No gradient for attribute {i}")
            grads.append(torch.zeros_like(target_param.view(-1)).detach())

    # 7. è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ
    grads_stack = torch.stack(grads)  # [40, D]
    sim_matrix = compute_cosine_similarity(grads_stack)  # [40, 40] numpy

    # 8. ç»˜å›¾
    print(f"ğŸ¨ Plotting heatmap to {args.output}...")
    plt.figure(figsize=(20, 16))

    # ä½¿ç”¨ Seaborn ç»˜åˆ¶çƒ­åŠ›å›¾
    # vmin=-1 (å®Œå…¨å†²çª), vmax=1 (å®Œå…¨ä¸€è‡´), center=0 (æ­£äº¤)
    ax = sns.heatmap(
        sim_matrix,
        cmap='RdBu_r',  # è“è‰²=è´Ÿç›¸å…³(å†²çª), çº¢è‰²=æ­£ç›¸å…³(ååŒ)
        vmin=-1, vmax=1, center=0,
        square=True,
        xticklabels=CELEBA_ATTRIBUTES,
        yticklabels=CELEBA_ATTRIBUTES
    )

    plt.title(f"Gradient Conflict Heatmap (Shared Encoder Last Layer)\nModel: Ours (CausalMTL)", fontsize=20)
    plt.xticks(rotation=90, fontsize=8)
    plt.yticks(rotation=0, fontsize=8)

    plt.tight_layout()
    plt.savefig(args.output, dpi=300)
    print(f"âœ… Done. Heatmap saved.")


if __name__ == '__main__':
    main()